#!/usr/bin/env python3
"""
YOLO ë¼ë²¨ë§ ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
RunwayRiskSim í”„ë¡œì íŠ¸ì˜ yolo_capture ë°ì´í„°ì˜ ë¼ë²¨ë§ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import os
import cv2
import numpy as np
import argparse
import glob
from pathlib import Path
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì°¾ê¸°
project_root = Path(__file__).parent.parent  # scripts/ -> RunwayRiskSim/

class YOLOLabelVisualizer:
    def __init__(self):
        # í´ë˜ìŠ¤ ì •ë³´ (YoloCaptureManager.csì—ì„œ í™•ì¸)
        self.class_names = {
            0: "Bird",
            1: "Airplane",
            2: "FOD",
            3: "Animal",
            5: "Fire",
            6: "Car",
            7: "Person"
        }
        
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ (BGR í˜•ì‹)
        self.class_colors = {
            0: (0, 255, 0),    # ì´ˆë¡ìƒ‰ - Bird
            4: (0, 0, 255),    # ë¹¨ê°„ìƒ‰ - Airplane
        }
        
        # ê¸°ë³¸ ìƒ‰ìƒ (ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤ìš©)
        self.default_color = (0, 255, 255)  # ë…¸ë€ìƒ‰
    
    def parse_yolo_label(self, label_path):
        """
        YOLO ë¼ë²¨ íŒŒì¼ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
        Returns: list of (class_id, center_x, center_y, width, height)
        """
        detections = []
        
        if not os.path.exists(label_path):
            return detections
            
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
                
            for line in lines:
                line = line.strip()
                if not line:  # ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸°
                    continue
                    
                parts = line.split()
                if len(parts) == 5:
                    class_id = int(parts[0])
                    center_x = float(parts[1])
                    center_y = float(parts[2])
                    width = float(parts[3])
                    height = float(parts[4])
                    
                    detections.append((class_id, center_x, center_y, width, height))
                    
        except Exception as e:
            print(f"âš ï¸  ë¼ë²¨ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜ {label_path}: {e}")
            
        return detections
    
    def draw_detection(self, image, detection, img_width, img_height, show_details=False):
        """
        ì´ë¯¸ì§€ì— detection ë°•ìŠ¤ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        """
        class_id, center_x, center_y, width, height = detection
        
        # ì •ê·œí™”ëœ ì¢Œí‘œë¥¼ ì‹¤ì œ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
        center_x_px = int(center_x * img_width)
        center_y_px = int(center_y * img_height)
        width_px = int(width * img_width)
        height_px = int(height * img_height)
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê³„ì‚°
        x1 = int(center_x_px - width_px / 2)
        y1 = int(center_y_px - height_px / 2)
        x2 = int(center_x_px + width_px / 2)
        y2 = int(center_y_px + height_px / 2)
        
        # ì¢Œí‘œ ë²”ìœ„ ì œí•œ
        x1 = max(0, min(x1, img_width - 1))
        y1 = max(0, min(y1, img_height - 1))
        x2 = max(0, min(x2, img_width - 1))
        y2 = max(0, min(y2, img_height - 1))
        
        # ìƒ‰ìƒ ë° í´ë˜ìŠ¤ëª… ì„ íƒ
        color = self.class_colors.get(class_id, self.default_color)
        class_name = self.class_names.get(class_id, f"Class_{class_id}")
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)
        
        # ì¤‘ì‹¬ì  ê·¸ë¦¬ê¸°
        cv2.circle(image, (center_x_px, center_y_px), 4, color, -1)
        cv2.circle(image, (center_x_px, center_y_px), 4, (255, 255, 255), 1)
        
        # ë¼ë²¨ í…ìŠ¤íŠ¸
        if show_details:
            label_text = f"{class_name} ({center_x:.3f}, {center_y:.3f}) [{width_px}x{height_px}]"
        else:
            label_text = f"{class_name}"
        
        # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 1
        (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, thickness)
        
        # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
        text_x = x1
        text_y = y1 - 10 if y1 > 30 else y2 + 25
        
        cv2.rectangle(image, 
                     (text_x, text_y - text_height - baseline - 2), 
                     (text_x + text_width + 4, text_y + baseline), 
                     color, -1)
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        cv2.putText(image, label_text, (text_x + 2, text_y - 2), 
                   font, font_scale, (255, 255, 255), thickness)
        
        return image
    
    def visualize_single_image(self, image_path, label_path, output_path=None, show=False, show_details=False):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì™€ ë¼ë²¨ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
        """
        if not os.path.exists(image_path):
            print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None
            
        # ì´ë¯¸ì§€ ì½ê¸°
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None
            
        img_height, img_width = image.shape[:2]
        
        # ë¼ë²¨ íŒŒì‹±
        detections = self.parse_yolo_label(label_path)
        
        # ê° detection ê·¸ë¦¬ê¸°
        for detection in detections:
            image = self.draw_detection(image, detection, img_width, img_height, show_details)
        
        # ì´ë¯¸ì§€ ì •ë³´ í…ìŠ¤íŠ¸ ì¶”ê°€
        frame_name = os.path.basename(image_path).split('.')[0]
        info_text = f"Frame: {frame_name} | Objects: {len(detections)} | Size: {img_width}x{img_height}"
        
        # ì •ë³´ í…ìŠ¤íŠ¸ ë°°ê²½
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        (text_width, text_height), baseline = cv2.getTextSize(info_text, font, font_scale, thickness)
        
        cv2.rectangle(image, (10, 10), (text_width + 20, text_height + baseline + 20), (0, 0, 0), -1)
        cv2.putText(image, info_text, (15, text_height + 15), font, font_scale, (255, 255, 255), thickness)
        
        # í´ë˜ìŠ¤ë³„ í†µê³„ í‘œì‹œ
        class_counts = {}
        for detection in detections:
            class_id = detection[0]
            class_name = self.class_names.get(class_id, f"Class_{class_id}")
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        y_offset = text_height + 40
        for class_name, count in class_counts.items():
            class_text = f"{class_name}: {count}"
            cv2.putText(image, class_text, (15, y_offset), font, 0.5, (255, 255, 255), 1)
            y_offset += 20
        
        # ì¶œë ¥ ì²˜ë¦¬
        if output_path:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            cv2.imwrite(output_path, image)
            
        if show:
            cv2.imshow('YOLO Label Visualization', image)
            key = cv2.waitKey(0)
            cv2.destroyAllWindows()
            return key  # ESC í‚¤ ë“±ìœ¼ë¡œ ì¢…ë£Œ ì œì–´ ê°€ëŠ¥
            
        return image
    
    def visualize_camera_batch(self, camera_path, output_dir=None, max_images=50, show_progress=True):
        """
        ì¹´ë©”ë¼ í´ë”ì˜ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
        """
        camera_name = os.path.basename(camera_path)
        print(f"\nğŸ¥ ì¹´ë©”ë¼ {camera_name} ì²˜ë¦¬ ì¤‘...")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸° (í”„ë ˆì„ ë²ˆí˜¸ìˆœ ì •ë ¬)
        image_files = sorted(glob.glob(os.path.join(camera_path, "frame_*.png")), 
                           key=lambda x: int(os.path.basename(x).split('_')[1].split('.')[0]))
        
        if not image_files:
            print(f"âŒ {camera_path}ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return {}
            
        # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
        if len(image_files) > max_images:
            print(f"ğŸ“Š {len(image_files)}ê°œ ì´ë¯¸ì§€ ì¤‘ ìµœì‹  {max_images}ê°œë§Œ ì²˜ë¦¬")
            image_files = image_files[-max_images:]  # ìµœì‹  ì´ë¯¸ì§€ë“¤ ì„ íƒ
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if output_dir:
            camera_output_dir = os.path.join(output_dir, camera_name)
            os.makedirs(camera_output_dir, exist_ok=True)
        
        stats = {
            "total": 0, 
            "with_objects": 0, 
            "empty": 0,
            "classes": {},
            "total_objects": 0
        }
        
        for i, image_path in enumerate(image_files):
            if show_progress and i % 10 == 0:
                print(f"  ì§„í–‰ë¥ : {i+1}/{len(image_files)} ({(i+1)/len(image_files)*100:.1f}%)")
                
            # ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
            label_path = image_path.replace('.png', '.txt')
            
            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            output_path = None
            if output_dir:
                output_filename = f"labeled_{os.path.basename(image_path)}"
                output_path = os.path.join(camera_output_dir, output_filename)
            
            # ì‹œê°í™”
            result_image = self.visualize_single_image(image_path, label_path, output_path)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            if result_image is not None:
                stats["total"] += 1
                detections = self.parse_yolo_label(label_path)
                
                if detections:
                    stats["with_objects"] += 1
                    stats["total_objects"] += len(detections)
                    
                    # í´ë˜ìŠ¤ë³„ í†µê³„
                    for detection in detections:
                        class_id = detection[0]
                        class_name = self.class_names.get(class_id, f"Class_{class_id}")
                        stats["classes"][class_name] = stats["classes"].get(class_name, 0) + 1
                else:
                    stats["empty"] += 1
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“ˆ {camera_name} ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"   - ì´ ì´ë¯¸ì§€: {stats['total']}ê°œ")
        print(f"   - ê°ì²´ í¬í•¨: {stats['with_objects']}ê°œ")
        print(f"   - ë¹ˆ í”„ë ˆì„: {stats['empty']}ê°œ")
        print(f"   - ì´ ê°ì²´ ìˆ˜: {stats['total_objects']}ê°œ")
        if stats['total'] > 0:
            print(f"   - ê°ì²´ ê²€ì¶œë¥ : {stats['with_objects']/stats['total']*100:.1f}%")
            print(f"   - í‰ê·  ê°ì²´/í”„ë ˆì„: {stats['total_objects']/stats['total']:.1f}ê°œ")
        
        if stats['classes']:
            print(f"   - í´ë˜ìŠ¤ë³„ ë¶„í¬:")
            for class_name, count in sorted(stats['classes'].items()):
                percentage = count / stats['total_objects'] * 100 if stats['total_objects'] > 0 else 0
                print(f"     * {class_name}: {count}ê°œ ({percentage:.1f}%)")
        
        return stats
    
    def analyze_dataset(self, yolo_capture_path):
        """
        ì „ì²´ ë°ì´í„°ì…‹ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        print("ğŸ” ë°ì´í„°ì…‹ ë¶„ì„ ì¤‘...")
        
        camera_dirs = [d for d in os.listdir(yolo_capture_path) 
                      if os.path.isdir(os.path.join(yolo_capture_path, d)) and 
                      d.startswith('Fixed_Camera_')]
        
        if not camera_dirs:
            print("âŒ ì¹´ë©”ë¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        total_stats = {
            "images": 0, 
            "labels": 0, 
            "objects": 0, 
            "empty_frames": 0,
            "classes": {}
        }
        camera_stats = {}
        
        for camera_dir in sorted(camera_dirs):
            camera_path = os.path.join(yolo_capture_path, camera_dir)
            
            # ì´ë¯¸ì§€ì™€ ë¼ë²¨ íŒŒì¼ ê°œìˆ˜
            images = glob.glob(os.path.join(camera_path, "frame_*.png"))
            labels = glob.glob(os.path.join(camera_path, "frame_*.txt"))
            
            camera_objects = 0
            camera_empty = 0
            camera_classes = {}
            
            # ê° ë¼ë²¨ íŒŒì¼ ë¶„ì„
            for label_path in labels:
                detections = self.parse_yolo_label(label_path)
                if detections:
                    camera_objects += len(detections)
                    for detection in detections:
                        class_id = detection[0]
                        class_name = self.class_names.get(class_id, f"Class_{class_id}")
                        
                        total_stats["classes"][class_name] = total_stats["classes"].get(class_name, 0) + 1
                        camera_classes[class_name] = camera_classes.get(class_name, 0) + 1
                else:
                    camera_empty += 1
            
            camera_stats[camera_dir] = {
                "images": len(images),
                "labels": len(labels),
                "objects": camera_objects,
                "empty_frames": camera_empty,
                "classes": camera_classes
            }
            
            print(f"ğŸ“¹ {camera_dir}:")
            print(f"   - ì´ë¯¸ì§€: {len(images)}ê°œ, ë¼ë²¨: {len(labels)}ê°œ")
            print(f"   - ê°ì²´: {camera_objects}ê°œ, ë¹ˆ í”„ë ˆì„: {camera_empty}ê°œ")
            if len(labels) > 0:
                print(f"   - ê²€ì¶œë¥ : {(len(labels)-camera_empty)/len(labels)*100:.1f}%")
            
            total_stats["images"] += len(images)
            total_stats["labels"] += len(labels)
            total_stats["objects"] += camera_objects
            total_stats["empty_frames"] += camera_empty
        
        print(f"\nğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ í†µê³„:")
        print(f"   - ì´ ì´ë¯¸ì§€: {total_stats['images']}ê°œ")
        print(f"   - ì´ ë¼ë²¨: {total_stats['labels']}ê°œ")
        print(f"   - ì´ ê°ì²´: {total_stats['objects']}ê°œ")
        print(f"   - ë¹ˆ í”„ë ˆì„: {total_stats['empty_frames']}ê°œ")
        
        if total_stats['labels'] > 0:
            detection_rate = (total_stats['labels']-total_stats['empty_frames'])/total_stats['labels']*100
            print(f"   - ê°ì²´ ê²€ì¶œë¥ : {detection_rate:.1f}%")
            
        if total_stats['objects'] > 0:
            avg_objects = total_stats['objects']/total_stats['labels']
            print(f"   - í‰ê·  ê°ì²´/í”„ë ˆì„: {avg_objects:.1f}ê°œ")
        
        if total_stats['classes']:
            print(f"\nğŸ·ï¸  í´ë˜ìŠ¤ë³„ ë¶„í¬:")
            for class_name, count in sorted(total_stats['classes'].items()):
                percentage = count / total_stats['objects'] * 100 if total_stats['objects'] > 0 else 0
                print(f"   - {class_name}: {count}ê°œ ({percentage:.1f}%)")
        
        return {"total": total_stats, "cameras": camera_stats}
    
    def create_summary_report(self, stats, output_dir):
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        """
        if not output_dir:
            return
            
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report = {
            "timestamp": timestamp,
            "analysis_time": datetime.now().isoformat(),
            "statistics": stats
        }
        
        report_path = os.path.join(output_dir, f"yolo_analysis_report_{timestamp}.json")
        os.makedirs(output_dir, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

def main():
    parser = argparse.ArgumentParser(description='YOLO ë¼ë²¨ë§ ì‹œê°í™” ë„êµ¬ - RunwayRiskSim')
    parser.add_argument('--input', '-i', default='data/yolo_capture', 
                       help='yolo_capture ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: data/yolo_capture)')
    parser.add_argument('--output', '-o', default='data/yolo_visualization', 
                       help='ì‹œê°í™”ëœ ì´ë¯¸ì§€ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/yolo_visualization)')
    parser.add_argument('--camera', '-c', 
                       help='íŠ¹ì • ì¹´ë©”ë¼ë§Œ ì²˜ë¦¬ (ì˜ˆ: Fixed_Camera_A)')
    parser.add_argument('--max-images', '-m', type=int, default=50, 
                       help='ì¹´ë©”ë¼ë‹¹ ìµœëŒ€ ì²˜ë¦¬ ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 50)')
    parser.add_argument('--analyze-only', '-a', action='store_true', 
                       help='ë¶„ì„ë§Œ ìˆ˜í–‰ (ì‹œê°í™” ì•ˆí•¨)')
    parser.add_argument('--show', '-s', action='store_true', 
                       help='ì‹œê°í™” ê²°ê³¼ë¥¼ í™”ë©´ì— í‘œì‹œ')
    parser.add_argument('--details', '-d', action='store_true',
                       help='ìƒì„¸ ì •ë³´ í‘œì‹œ (ì¢Œí‘œ, í¬ê¸° ë“±)')
    parser.add_argument('--no-save', action='store_true',
                       help='ì´ë¯¸ì§€ ì €ì¥í•˜ì§€ ì•ŠìŒ')
    
    args = parser.parse_args()
    
    # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    if not os.path.isabs(args.input):
        args.input = os.path.join(project_root, args.input)
    if not os.path.isabs(args.output):
        args.output = os.path.join(project_root, args.output)
    
    visualizer = YOLOLabelVisualizer()
    
    # ì…ë ¥ ê²½ë¡œ í™•ì¸
    if not os.path.exists(args.input):
        print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        return
    
    print(f"ğŸ“ ì…ë ¥ ë””ë ‰í† ë¦¬: {args.input}")
    if not args.no_save:
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {args.output}")
    
    # ë°ì´í„°ì…‹ ë¶„ì„
    stats = visualizer.analyze_dataset(args.input)
    
    # ë¶„ì„ ê²°ê³¼ ì €ì¥
    if not args.no_save:
        visualizer.create_summary_report(stats, args.output)
    
    if args.analyze_only:
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = None if args.no_save else args.output
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # íŠ¹ì • ì¹´ë©”ë¼ ì²˜ë¦¬
    if args.camera:
        camera_path = os.path.join(args.input, args.camera)
        if os.path.exists(camera_path):
            print(f"\nğŸ¯ íŠ¹ì • ì¹´ë©”ë¼ ì²˜ë¦¬: {args.camera}")
            visualizer.visualize_camera_batch(camera_path, output_dir, args.max_images)
        else:
            print(f"âŒ ì¹´ë©”ë¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {camera_path}")
    else:
        # ëª¨ë“  ì¹´ë©”ë¼ ì²˜ë¦¬
        camera_dirs = [d for d in os.listdir(args.input) 
                      if os.path.isdir(os.path.join(args.input, d)) and 
                      d.startswith('Fixed_Camera_')]
        
        if not camera_dirs:
            print("âŒ ì²˜ë¦¬í•  ì¹´ë©”ë¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ¬ ì´ {len(camera_dirs)}ê°œ ì¹´ë©”ë¼ ì²˜ë¦¬ ì‹œì‘")
        
        for camera_dir in sorted(camera_dirs):
            camera_path = os.path.join(args.input, camera_dir)
            try:
                visualizer.visualize_camera_batch(camera_path, output_dir, args.max_images)
            except KeyboardInterrupt:
                print("\nâ¹ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
                break
            except Exception as e:
                print(f"âŒ {camera_dir} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
    
    print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
    if output_dir:
        print(f"ğŸ“ ê²°ê³¼ í™•ì¸: {output_dir}")

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
"""
Base ëª¨ë¸ STT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (RTX 2060 ìµœì í™”)
"""

import time
from stt.whisper_engine import WhisperSTTEngine
from audio_io.mic_speaker_io import AudioIO

def test_base_model():
    """Base ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("=== Base ëª¨ë¸ STT í…ŒìŠ¤íŠ¸ (RTX 2060 ìµœì í™”) ===")
    
    # STT ì—”ì§„ ì´ˆê¸°í™” (base ëª¨ë¸, GPU ìë™ ì„ íƒ)
    print("1. STT ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    stt_engine = WhisperSTTEngine(model_name="base", language="ko", device="auto")
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    model_info = stt_engine.get_model_info()
    print("\nëª¨ë¸ ì •ë³´:")
    for key, value in model_info.items():
        print(f"  {key}: {value}")
    
    if not stt_engine.is_model_loaded():
        print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        return
    
    print("\nâœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ!")
    
    # ì˜¤ë””ì˜¤ IO ì´ˆê¸°í™”
    print("\n2. ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    audio_io = AudioIO()
    
    # í…ŒìŠ¤íŠ¸ ë…¹ìŒ
    print("\n3. ìŒì„± ë…¹ìŒ í…ŒìŠ¤íŠ¸")
    print("5ì´ˆ í›„ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ë§í•´ë³´ì„¸ìš”:")
    print("- 'FALCON 123 í™œì£¼ë¡œ ìƒíƒœ í™•ì¸ ìš”ì²­'")
    print("- 'FALCON 456 ì¡°ë¥˜ ìœ„í—˜ë„ ì²´í¬'")
    print("- 'FALCON 789 ì°©ë¥™ í—ˆê°€ ìš”ì²­'")
    
    # ì¹´ìš´íŠ¸ë‹¤ìš´
    for i in range(5, 0, -1):
        print(f"ì‹œì‘ê¹Œì§€ {i}ì´ˆ...")
        time.sleep(1)
    
    print("\nğŸ¤ ë…¹ìŒ ì‹œì‘! (5ì´ˆê°„)")
    start_time = time.time()
    audio_data = audio_io.record_audio(5.0)
    record_time = time.time() - start_time
    
    if not audio_data:
        print("âŒ ë…¹ìŒ ì‹¤íŒ¨")
        return
    
    print(f"âœ… ë…¹ìŒ ì™„ë£Œ ({record_time:.1f}ì´ˆ, {len(audio_data)} bytes)")
    
    # STT ì²˜ë¦¬
    print("\n4. ìŒì„± ì¸ì‹ ì²˜ë¦¬ ì¤‘...")
    start_time = time.time()
    text, confidence = stt_engine.transcribe_with_confidence(audio_data, "test_session")
    stt_time = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n=== STT ê²°ê³¼ ===")
    print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{text}'")
    print(f"ì‹ ë¢°ë„ ì ìˆ˜: {confidence:.3f}")
    print(f"ì²˜ë¦¬ ì‹œê°„: {stt_time:.2f}ì´ˆ")
    print(f"ì‹¤ì‹œê°„ ë¹„ìœ¨: {stt_time/record_time:.2f}x")
    
    # ì„±ëŠ¥ í‰ê°€
    if stt_time < record_time:
        print("ğŸš€ ì‹¤ì‹œê°„ë³´ë‹¤ ë¹ ë¥¸ ì²˜ë¦¬ (ìš°ìˆ˜)")
    elif stt_time < record_time * 2:
        print("âš¡ ì‹¤ì‹œê°„ ëŒ€ë¹„ 2ë°° ì´ë‚´ (ì–‘í˜¸)")
    else:
        print("ğŸŒ ì‹¤ì‹œê°„ ëŒ€ë¹„ 2ë°° ì´ˆê³¼ (ê°œì„  í•„ìš”)")
    
    if confidence > 0.7:
        print("ğŸ¯ ë†’ì€ ì‹ ë¢°ë„ (ìš°ìˆ˜)")
    elif confidence > 0.5:
        print("ğŸ‘ ë³´í†µ ì‹ ë¢°ë„ (ì–‘í˜¸)")
    else:
        print("âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (ì¬ë…¹ìŒ ê¶Œì¥)")
    
    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    if stt_engine.device == "cuda":
        import torch
        allocated = torch.cuda.memory_allocated() / 1024**3
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {allocated:.2f}GB")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        test_base_model()
    except KeyboardInterrupt:
        print("\n\ní…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print("\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    print("Base ëª¨ë¸ì€ RTX 2060ì—ì„œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.")
    print("ì„±ëŠ¥ vs ì •í™•ë„:")
    print("- Base (GPU): ë¹ ë¦„, ë³´í†µ ì •í™•ë„ â­ ê¶Œì¥ (RTX 2060)")
    print("- Medium (CPU): ëŠë¦¼, ë†’ì€ ì •í™•ë„")
    print("- Large-v2 (CPU): ë§¤ìš° ëŠë¦¼, ìµœê³  ì •í™•ë„")

if __name__ == "__main__":
    main() 
#!/usr/bin/env python3
"""
Large ëª¨ë¸ GPU í…ŒìŠ¤íŠ¸ (100% ë©”ëª¨ë¦¬ ì‚¬ìš©)
"""

import time
from stt.whisper_engine import WhisperSTTEngine
from audio_io.mic_speaker_io import AudioIO

def test_large_gpu():
    """Large ëª¨ë¸ GPU í…ŒìŠ¤íŠ¸"""
    print("=== Large ëª¨ë¸ GPU í…ŒìŠ¤íŠ¸ (100% ë©”ëª¨ë¦¬) ===")
    
    # STT ì—”ì§„ ì´ˆê¸°í™” (Large ëª¨ë¸)
    print("1. STT ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
    stt_engine = WhisperSTTEngine(model_name="large-v2", language="en", device="auto")
    
    # ëª¨ë¸ ì •ë³´ ì¶œë ¥
    print(f"\nëª¨ë¸ ì •ë³´:")
    print(f"  ëª¨ë¸ëª…: {stt_engine.model_name}")
    print(f"  ì¥ì¹˜: {stt_engine.device}")
    print(f"  ì–¸ì–´: {stt_engine.language}")
    print(f"  ë¡œë”© ìƒíƒœ: {stt_engine.is_model_loaded()}")
    
    if not stt_engine.is_model_loaded():
        print("âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨")
        return
    
    print("âœ… Large ëª¨ë¸ GPU ë¡œë”© ì„±ê³µ!")
    
    # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    import torch
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        gpu_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {gpu_memory:.2f}GB / {gpu_total:.2f}GB ({gpu_memory/gpu_total*100:.1f}%)")
    
    # ì˜¤ë””ì˜¤ IO ì´ˆê¸°í™”
    print("\n2. ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    audio_io = AudioIO()
    
    # ìŒì„± í…ŒìŠ¤íŠ¸
    print("\n3. Large ëª¨ë¸ ì˜ì–´ í•­ê³µ í†µì‹  í…ŒìŠ¤íŠ¸")
    print("5ì´ˆ í›„ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì˜ì–´ë¡œ ë§í•´ì£¼ì„¸ìš”:")
    print("- 'FALCON 123 runway status check'")
    print("- 'FALCON 456 bird risk assessment'")
    print("- 'FALCON 789 request landing clearance runway 25 left'")
    print("- 'FALCON 101 system status check'")
    print("- 'FALCON 202 FOD check runway 25L'")
    
    # ì¹´ìš´íŠ¸ë‹¤ìš´
    for i in range(5, 0, -1):
        print(f"ì‹œì‘ê¹Œì§€ {i}ì´ˆ...")
        time.sleep(1)
    
    print("\nğŸ¤ ë…¹ìŒ ì‹œì‘! (5ì´ˆê°„)")
    start_time = time.time()
    audio_data = audio_io.record_audio(5.0)
    record_time = time.time() - start_time
    
    if not audio_data:
        print("âŒ ë…¹ìŒ ì‹¤íŒ¨")
        return
    
    print(f"âœ… ë…¹ìŒ ì™„ë£Œ ({record_time:.1f}ì´ˆ, {len(audio_data)} bytes)")
    
    # STT ì²˜ë¦¬
    print(f"\n4. Large ëª¨ë¸ ìŒì„± ì¸ì‹ ì²˜ë¦¬...")
    print("â³ Large ëª¨ë¸ì€ ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
    start_time = time.time()
    text, confidence = stt_engine.transcribe_with_confidence(audio_data, "large_test")
    stt_time = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n=== Large ëª¨ë¸ ì¸ì‹ ê²°ê³¼ ===")
    print(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{text}'")
    print(f"ì‹ ë¢°ë„: {confidence:.3f}")
    print(f"ì²˜ë¦¬ ì‹œê°„: {stt_time:.2f}ì´ˆ")
    print(f"ì‹¤ì‹œê°„ ë¹„ìœ¨: {stt_time/record_time:.2f}x")
    
    # ì„±ëŠ¥ í‰ê°€
    if stt_time < record_time:
        print("âš¡ ì‹¤ì‹œê°„ë³´ë‹¤ ë¹ ë¦„ (ìš°ìˆ˜)")
    elif stt_time < record_time * 2:
        print("ğŸš€ ì‹¤ì‹œê°„ì˜ 2ë°° ì´ë‚´ (ì–‘í˜¸)")
    elif stt_time < record_time * 5:
        print("ğŸŒ ì‹¤ì‹œê°„ì˜ 5ë°° ì´ë‚´ (í—ˆìš©)")
    else:
        print("ğŸŒğŸŒ ì‹¤ì‹œê°„ì˜ 5ë°° ì´ˆê³¼ (ëŠë¦¼)")
    
    if confidence > 0.9:
        print("ğŸ¯ ìµœê³  ì‹ ë¢°ë„ (íƒì›”)")
    elif confidence > 0.8:
        print("ğŸ¯ ë†’ì€ ì‹ ë¢°ë„ (ìš°ìˆ˜)")
    elif confidence > 0.6:
        print("ğŸ‘ ë³´í†µ ì‹ ë¢°ë„ (ì–‘í˜¸)")
    else:
        print("âš ï¸ ë‚®ì€ ì‹ ë¢°ë„ (ì¬ë…¹ìŒ ê¶Œì¥)")
    
    # ì˜ì–´ í•­ê³µ ìš©ì–´ ì¸ì‹ í™•ì¸
    text_upper = text.upper()
    aviation_terms = ["FALCON", "RUNWAY", "LANDING", "BIRD", "SYSTEM", "FOD", "CLEARANCE", "CHECK", "STATUS", "REQUEST"]
    recognized_terms = [term for term in aviation_terms if term in text_upper]
    
    if recognized_terms:
        print(f"âœ… ì¸ì‹ëœ í•­ê³µ ìš©ì–´: {', '.join(recognized_terms)}")
    else:
        print("âŒ í•­ê³µ ìš©ì–´ ì¸ì‹ ì‹¤íŒ¨")
    
    # ìˆ«ì ì¸ì‹ í™•ì¸
    import re
    numbers = re.findall(r'\d+', text)
    if numbers:
        print(f"âœ… ì¸ì‹ëœ ìˆ«ì: {', '.join(numbers)}")
    else:
        print("âŒ ìˆ«ì ì¸ì‹ ì‹¤íŒ¨")
    
    # ìµœì¢… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated() / 1024**3
        print(f"\nğŸ’¾ ìµœì¢… GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {gpu_memory:.2f}GB")

def main():
    try:
        test_large_gpu()
    except KeyboardInterrupt:
        print("\ní…ŒìŠ¤íŠ¸ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n=== Large ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
    print("ğŸ† Large-v2: ìµœê³  ì •í™•ë„ ëª¨ë¸")
    print("ğŸ‡ºğŸ‡¸ ì™„ì „íˆ ì˜ì–´ë¡œ ì„¤ì •")
    print("âœˆï¸ ICAO êµ­ì œ í•­ê³µ í‘œì¤€ ì¤€ìˆ˜")
    print("ğŸš€ GPU 100% í™œìš©")

if __name__ == "__main__":
    main() 
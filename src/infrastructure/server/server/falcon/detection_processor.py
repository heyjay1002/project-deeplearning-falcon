"""
ê²€ì¶œ í”„ë¡œì„¸ì„œ ëª¨ë“ˆ
- ê°ì²´ ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
- ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
- ê²€ì¶œ í†µê³„ ê´€ë¦¬
"""

import cv2
import numpy as np
from PyQt6.QtCore import QThread, pyqtSignal
import time
from datetime import datetime
from db.repository import DetectionRepository
from config import DB_HOST, DB_PORT, DB_USER, DB_PASSWORD, DB_NAME
import os

from config import *

class FPSCalculator:
    """FPS ê³„ì‚°ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    def __init__(self):
        self.frame_count = 0
        self.last_time = time.time()
        self.current_fps = 0
    
    def update(self):
        self.frame_count += 1
        current_time = time.time()
        elapsed = current_time - self.last_time
        
        if elapsed >= 1.0:
            self.current_fps = self.frame_count / elapsed
            self.frame_count = 0
            self.last_time = current_time
            return True
        return False

class DetectionProcessor(QThread):
    """ê°ì²´ ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬ë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    # ì‹œê·¸ë„ ì •ì˜
    detection_processed = pyqtSignal(dict)  # ì²˜ë¦¬ëœ ê²€ì¶œ ê²°ê³¼ ì „ë‹¬ìš© ì‹œê·¸ë„
    stats_ready = pyqtSignal(dict)  # í†µê³„ ì „ë‹¬ìš© ì‹œê·¸ë„
    
    def __init__(self, video_processor=None):
        super().__init__()
        # ê²€ì¶œ ê²°ê³¼ ë²„í¼
        self.detection_buffer = {}
        
        # FPS ê³„ì‚°ê¸°
        self.fps_calc = FPSCalculator()
        
        # ë§ˆì§€ë§‰ ì²˜ë¦¬ ê²°ê³¼ ì €ì¥
        self.last_detection = None
        self.last_detection_img_id = None
        
        # ê²½ê³  ì „ì†¡ëœ ê°ì²´ ID ì¶”ì  (ë©”ëª¨ë¦¬ ìºì‹œ)
        self.alerted_object_ids = set()
        
        # êµ¬ì¡° ìƒí™© ê²½í—˜í•œ ê°ì²´ IDì™€ ë ˆë²¨ ì¶”ì  (ë ˆë²¨ ë³€í™” ì‹œ ì¬ì „ì†¡)
        self.alerted_rescue_levels = {}  # {object_id: rescue_level}
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë¦¬í¬ì§€í† ë¦¬ ì´ˆê¸°í™”
        self.repository = DetectionRepository(
            host=DB_HOST,
            port=DB_PORT,
            user=DB_USER,
            password=DB_PASSWORD,
            database=DB_NAME
        )
        
        # VideoProcessor ì°¸ì¡° ì €ì¥
        self.video_processor = video_processor
        
        # ì‹¤í–‰ ìƒíƒœ
        self.running = True
    
    def process_detection(self, detection_data):
        """ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
        Args:
            detection_data (dict): {
                'img_id': int,  # ì´ë¯¸ì§€ ID
                'detections': list  # ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            }
        """
        if not detection_data or 'detections' not in detection_data:
            return
        
        img_id = detection_data['img_id']
        detections = detection_data['detections']
        
        # ê²€ì¶œ ê²°ê³¼ ë²„í¼ì— ì €ì¥
        self.detection_buffer[img_id] = detections
        
        # ë§ˆì§€ë§‰ ê²€ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸
        self.last_detection = detections
        self.last_detection_img_id = img_id
        
        # ì²˜ë¦¬ëœ ê²€ì¶œ ê²°ê³¼ ì „ë‹¬
        processed_data = {
            'detections': detections,
            'img_id': img_id
        }
        self.detection_processed.emit(processed_data)
        
        # FPS ê³„ì‚° ë° í†µê³„ ì—…ë°ì´íŠ¸
        if self.fps_calc.update():
            stats = {
                'fps': round(self.fps_calc.current_fps, 1)
            }
            self.stats_ready.emit(stats)
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            if detections:
                # print(f"[DEBUG] í˜„ì¬ ì¶”ì  ì¤‘ì¸ ì¼ë°˜ ê°ì²´: {len(self.alerted_object_ids)}ê°œ")
                # print(f"[DEBUG] í˜„ì¬ ì¶”ì  ì¤‘ì¸ êµ¬ì¡° ê°ì²´: {len(self.alerted_rescue_levels)}ê°œ")
                # ìµœì´ˆ ê²½ê³ ëœ ê°ì²´ë“¤ + ìµœì´ˆ êµ¬ì¡° ìƒí™© í•„í„°ë§
                new_detections = []
                for detection in detections:
                    object_id = detection['object_id']
                    event_type = detection.get('event_type', 2)  # ê¸°ë³¸ê°’: UNAUTH
                    
                    # print(f"[DEBUG] ê°ì§€ ê°ì²´ í™•ì¸: object_id={object_id}, event_type={event_type}")
                    
                    if event_type == 3:  # êµ¬ì¡° ìƒí™©
                        if object_id not in self.alerted_rescue_levels:  # ìµœì´ˆë§Œ
                            new_detections.append(detection)
                            rescue_level = detection.get('rescue_level', 0)
                            print(f"[INFO] âœ… ìµœì´ˆ êµ¬ì¡°: object_id={object_id}, rescue_level={rescue_level}")
                        # ì´ë¯¸ ì²˜ë¦¬ëœ êµ¬ì¡° ê°ì²´ëŠ” ë¬´ì‹œ
                    elif object_id not in self.alerted_object_ids:  # ì¼ë°˜ ìƒí™©
                        new_detections.append(detection)
                        # ê²½ê³  ëª©ë¡ ì¶”ê°€ëŠ” ì‹¤ì œ ì²˜ë¦¬ ì„±ê³µ í›„ì— í•¨
                        print(f"[INFO] ìµœì´ˆ ì¼ë°˜ ìœ„ë°˜ ê°ì§€: object_id={object_id}, event_type={event_type}")
                    else:
                        # print(f"[DEBUG] ì´ë¯¸ ì²˜ë¦¬ëœ ê°ì²´: object_id={object_id}, event_type={event_type}")
                        pass
                
                # ìµœì´ˆ ê²½ê³ ëœ ê°ì²´ë“¤ì— ëŒ€í•´ì„œë§Œ ì´ë¯¸ì§€ ìƒì„± ë° DB ì €ì¥
                # print(f"[DEBUG] ìµœì´ˆ ê°ì§€ ê°ì²´ ìˆ˜: {len(new_detections)}")
                if new_detections:
                    # êµ¬ì¡° ìƒí™© í¬í•¨ ì—¬ë¶€ í™•ì¸
                    rescue_count = sum(1 for det in new_detections if det.get('event_type') == 3)
                    if rescue_count > 0:
                        print(f"[INFO] ğŸš¨ êµ¬ì¡° ê°ì²´ í¬í•¨: {rescue_count}ê°œ")
                    
                    if not self.video_processor:
                        print(f"[ERROR] video_processorê°€ Noneì…ë‹ˆë‹¤!")
                        return
                    
                if new_detections and self.video_processor:
                    # print(f"[DEBUG] í”„ë ˆì„ ìš”ì²­: img_id={img_id}")
                    
                    # # ë²„í¼ ìƒíƒœ í™•ì¸ (ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬)
                    # buffer_keys = list(self.video_processor.frame_buffer.keys())
                    # print(f"[DEBUG] ë²„í¼ ìƒíƒœ: {len(buffer_keys)}ê°œ í”„ë ˆì„ ì €ì¥ë¨")
                    # if buffer_keys:
                    #     min_id = min(buffer_keys)
                    #     max_id = max(buffer_keys)
                    #     print(f"[DEBUG] ë²„í¼ ë²”ìœ„: {min_id} ~ {max_id}")
                    #     print(f"[DEBUG] ìš”ì²­ img_id: {img_id}")
                    #     if img_id < min_id:
                    #         print(f"[ERROR] img_idê°€ ë„ˆë¬´ ì˜¤ë˜ë¨ (ìµœì†Œ: {min_id})")
                    #     elif img_id > max_id:
                    #         print(f"[ERROR] img_idê°€ ë„ˆë¬´ ìµœì‹ ì„ (ìµœëŒ€: {max_id})")
                    
                    frame = self.video_processor.get_frame(img_id)
                    if frame is not None:
                        # print(f"[DEBUG] í”„ë ˆì„ íšë“ ì„±ê³µ: img_id={img_id}")
                        pass
                    else:
                        print(f"[ERROR] í”„ë ˆì„ íšë“ ì‹¤íŒ¨: img_id={img_id}")
                        return
                    
                    if frame is not None:
                        saved_detections = []
                        crop_imgs = []
                        for detection in new_detections:
                            # ì´ë¯¸ì§€ ì €ì¥ í›„ ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ë°›ê¸°
                            saved_img_path = self.save_cropped_frame(frame, detection, img_id)
                            if saved_img_path:
                                # detectionì— ì‹¤ì œ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ì¶”ê°€
                                detection['img_path'] = saved_img_path
                                
                                bbox = detection.get('bbox', [])
                                if bbox and len(bbox) == 4:
                                    x1, y1, x2, y2 = map(int, bbox)
                                    crop = frame[y1:y2, x1:x2]
                                    _, img_encoded = cv2.imencode('.jpg', crop)
                                    crop_imgs.append(img_encoded.tobytes())
                                    saved_detections.append(detection)
                        if saved_detections:
                            # print(f"[DEBUG] DB ì €ì¥ ì‹œë„: {len(saved_detections)}ê°œ ê°ì²´")
                            success = self.repository.save_detection_event(
                                camera_id='A',
                                img_id=img_id,
                                detections=saved_detections,
                                crop_imgs=crop_imgs
                            )
                            if success:
                                print(f"[INFO] ME_FD ì €ì¥ ì™„ë£Œ: {len(saved_detections)}ê°œ ê°ì²´")
                                # ME_FD ì²˜ë¦¬ ì„±ê³µ ì‹œì—ë§Œ alerted_object_idsì— ì¶”ê°€
                                for detection in saved_detections:
                                    object_id = detection['object_id']
                                    event_type = detection.get('event_type', 2)
                                    if event_type == 3:  # êµ¬ì¡° ìƒí™©
                                        rescue_level = detection.get('rescue_level', 0)
                                        self.alerted_rescue_levels[object_id] = rescue_level
                                        print(f"[INFO] ğŸš¨ êµ¬ì¡° ME_FD ì „ì†¡ ì™„ë£Œ: object_id={object_id}, rescue_level={rescue_level}")
                                    else:  # ì¼ë°˜ ìƒí™©
                                        self.alerted_object_ids.add(object_id)
                                        # print(f"[INFO] ì²˜ë¦¬ ì™„ë£Œ ë“±ë¡: object_id={object_id}")
                                        pass
                            else:
                                print(f"[ERROR] ME_FD ì €ì¥ ì‹¤íŒ¨: {len(saved_detections)}ê°œ ê°ì²´")
                                # DB ì €ì¥ ì‹¤íŒ¨ ì‹œì—ë„ ì¤‘ë³µ í‚¤ ì˜¤ë¥˜ë©´ ë“±ë¡ (ì´ë¯¸ DBì— ì¡´ì¬í•¨ì„ ì˜ë¯¸)
                                for detection in saved_detections:
                                    object_id = detection['object_id']
                                    event_type = detection.get('event_type', 2)
                                    if event_type == 3:  # êµ¬ì¡° ìƒí™©
                                        rescue_level = detection.get('rescue_level', 0)
                                        self.alerted_rescue_levels[object_id] = rescue_level
                                        print(f"[INFO] ğŸš¨ êµ¬ì¡° ìƒí™© ì¤‘ë³µ ë°©ì§€ ë“±ë¡: object_id={object_id}, rescue_level={rescue_level}")
                                    else:  # ì¼ë°˜ ìƒí™©
                                        self.alerted_object_ids.add(object_id)
                                        print(f"[INFO] ì¼ë°˜ ìƒí™© ì¤‘ë³µ ë°©ì§€ ë“±ë¡: object_id={object_id}")
                        else:
                            # print(f"[DEBUG] ì €ì¥í•  ê°ì²´ ì—†ìŒ: saved_detections ë¹„ì–´ìˆìŒ")
                            pass
            
        except Exception as e:
            print(f"[ERROR] ê°ì§€ ê²°ê³¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def draw_detections(self, frame, img_id):
        """ê²€ì¶œ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ì‹œê°í™”
        Args:
            frame (np.ndarray): ì›ë³¸ í”„ë ˆì„
            img_id (int): ì´ë¯¸ì§€ ID
        Returns:
            np.ndarray: ê²€ì¶œ ê²°ê³¼ê°€ ê·¸ë ¤ì§„ í”„ë ˆì„
        """
        frame_with_boxes = frame.copy()
        
        # ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë˜ëœ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬ (ë§¤ 50ë²ˆì§¸ í˜¸ì¶œë§ˆë‹¤)
        if hasattr(self, '_draw_count'):
            self._draw_count += 1
        else:
            self._draw_count = 1
            
        if self._draw_count % 50 == 0:
            self.cleanup_old_detections(img_id)
        
        # í˜„ì¬ í”„ë ˆì„ì˜ ê²€ì¶œ ê²°ê³¼ í™•ì¸
        if img_id in self.detection_buffer:
            detections = self.detection_buffer[img_id]
        else:
            # í˜„ì¬ í”„ë ˆì„ë³´ë‹¤ ì´ì „ì˜ ê°€ì¥ ê°€ê¹Œìš´ ê²€ì¶œ ê²°ê³¼ ì°¾ê¸°
            prev_frame_id = None
            for frame_id in self.detection_buffer.keys():
                if frame_id < img_id and (prev_frame_id is None or frame_id > prev_frame_id):
                    prev_frame_id = frame_id
            
            if prev_frame_id is not None:
                detections = self.detection_buffer[prev_frame_id]
            else:
                return frame_with_boxes
        
        # ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
        for detection in detections:
            bbox = detection.get('bbox', [])
            if not bbox or len(bbox) != 4:
                continue
            
            x1, y1, x2, y2 = map(int, bbox)
            cls = detection.get('class', 'Unknown')
            conf = detection.get('confidence', 0.0)
            
            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame_with_boxes, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # ë ˆì´ë¸” í‘œì‹œ
            label = f"{cls}: {conf:.2f}"
            (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)
            cv2.rectangle(frame_with_boxes, (x1, y1 - label_h - 10), (x1 + label_w, y1), (0, 255, 0), -1)
            cv2.putText(frame_with_boxes, label, (x1, y1 - 5),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)
        
        return frame_with_boxes
    
    def get_detection(self, img_id):
        """íŠ¹ì • ì´ë¯¸ì§€ IDì˜ ê²€ì¶œ ê²°ê³¼ ë°˜í™˜"""
        return self.detection_buffer.get(img_id)
    
    def clear_buffer(self):
        """ë²„í¼ ì´ˆê¸°í™”"""
        self.detection_buffer.clear()
        self.last_detection = None
        self.last_detection_img_id = None
    
    def stop(self):
        """ì²˜ë¦¬ ì¤‘ì§€"""
        self.running = False
        self.repository.close()

    def crop_frame(self, frame, detection):
        """bboxë¡œ í”„ë ˆì„ì„ cropí•˜ì—¬ ì´ë¯¸ì§€ë¡œ ì €ì¥
        Args:
            frame (np.ndarray): ì›ë³¸ í”„ë ˆì„
            detection (dict): ê²€ì¶œ ê²°ê³¼
        Returns:
            np.ndarray: ì €ì¥ëœ ì´ë¯¸ì§€
        """
        bbox = detection.get('bbox', [])
        if not bbox or len(bbox) != 4:
            return None
        
        x1, y1, x2, y2 = map(int, bbox)
        cropped_frame = frame[y1:y2, x1:x2]
        return cropped_frame

    def save_cropped_frame(self, frame, detection, img_id):
        cropped_frame = self.crop_frame(frame, detection)
        if cropped_frame is None:
            print(f"[ERROR] Crop ì‹¤íŒ¨: object_id={detection.get('object_id')}, bbox={detection.get('bbox')}")
            return None
        img_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'img')
        os.makedirs(img_dir, exist_ok=True)
        filename = f"img_{detection['object_id']}_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg"
        filepath = os.path.join(img_dir, filename)
        result = cv2.imwrite(filepath, cropped_frame)
        if result:
            print(f"[INFO] ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {filename}")
            return f"img/{filename}"  # DBì— ì €ì¥í•  ìƒëŒ€ ê²½ë¡œ ë°˜í™˜
        else:
            print(f"[ERROR] ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {filename}")
            return None

    def cleanup_old_detections(self, current_img_id, max_age_ns=1_000_000_000):
        """ì˜¤ë˜ëœ ê²€ì¶œ ê²°ê³¼ ì •ë¦¬ (5ì´ˆ ì´ìƒ or 50ê°œ ì´ìƒ)"""
        current_time = current_img_id
        old_keys = []
        
        for frame_id in self.detection_buffer.keys():
            if current_time - frame_id > max_age_ns:
                old_keys.append(frame_id)
        
        for key in old_keys:
            del self.detection_buffer[key]
        
        # if old_keys:
        #     print(f"[INFO] ë²„í¼ ì •ë¦¬: {len(old_keys)}ê°œ ì˜¤ë˜ëœ ê²€ì¶œ ê²°ê³¼ ì‚­ì œë¨ (ë²„í¼ í¬ê¸°: {len(self.detection_buffer)})") 